{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5300d1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\translit\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61a6c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1299155, 5)\n",
      "['unique_identifier', 'native word', 'english word', 'source', 'score']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>native word</th>\n",
       "      <th>english word</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hin1</td>\n",
       "      <td>जन्मदिवस</td>\n",
       "      <td>janamdivas</td>\n",
       "      <td>Dakshina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hin2</td>\n",
       "      <td>रक्खा</td>\n",
       "      <td>rakha</td>\n",
       "      <td>Dakshina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hin3</td>\n",
       "      <td>मिलीजुली</td>\n",
       "      <td>milijuli</td>\n",
       "      <td>Dakshina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_identifier native word english word    source  score\n",
       "0              hin1    जन्मदिवस   janamdivas  Dakshina    NaN\n",
       "1              hin2       रक्खा        rakha  Dakshina    NaN\n",
       "2              hin3    मिलीजुली     milijuli  Dakshina    NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test one file\n",
    "path = r\"D:\\devegiri_task\\data\\hin\\hin_train.json\"\n",
    "\n",
    "df = pd.read_json(path, lines=True)          # ← lines=True is important here too\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c6c21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIN    train: 1,299,155 rows\n",
      "TAM    train: 3,230,902 rows\n",
      "TEL    train: 2,429,562 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BASE = Path(r\"D:\\devegiri_task\\data\")\n",
    "\n",
    "langs = [\"hin\", \"tam\", \"tel\"]\n",
    "\n",
    "dfs_train = {}\n",
    "dfs_val   = {}\n",
    "\n",
    "for lang in langs:\n",
    "    train_path = BASE / lang / f\"{lang}_train.json\"\n",
    "    val_path   = BASE / lang / f\"{lang}_valid.json\"   # or _val.json, dev.json, ...\n",
    "\n",
    "    dfs_train[lang] = pd.read_json(train_path, lines=True)\n",
    "    dfs_val[lang]   = pd.read_json(val_path, lines=True)\n",
    "\n",
    "    print(f\"{lang.upper():6} train: {dfs_train[lang].shape[0]:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69635294",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang, df in dfs_train.items():\n",
    "    df[\"lang\"] = lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1592344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang, df in dfs_val.items():\n",
    "    df[\"lang\"] = lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76e005a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_identifier', 'native word', 'english word', 'source', 'score',\n",
       "       'lang'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_train['hin'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a103962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = pd.concat([dfs_train['hin'], dfs_train['tam'], dfs_train['tel']], ignore_index=True)\n",
    "df_train_all = df_train_all[['english word', 'native word','lang']].rename(columns={\n",
    "    'english word': 'roman',\n",
    "    'native word':  'native',\n",
    "    'lang': 'lang'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2903b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_all = pd.concat([dfs_val['hin'], dfs_val['tam'], dfs_val['tel']], ignore_index=True)\n",
    "df_val_all = df_val_all[['english word', 'native word','lang']].rename(columns={\n",
    "    'english word': 'roman',\n",
    "    'native word':  'native',\n",
    "    'lang': 'lang'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8bc620a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roman</th>\n",
       "      <th>native</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>janamdivas</td>\n",
       "      <td>जन्मदिवस</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rakha</td>\n",
       "      <td>रक्खा</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>milijuli</td>\n",
       "      <td>मिलीजुली</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaanchon</td>\n",
       "      <td>जांचों</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chamkata</td>\n",
       "      <td>चमकता</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        roman    native lang\n",
       "0  janamdivas  जन्मदिवस  hin\n",
       "1       rakha     रक्खा  hin\n",
       "2    milijuli  मिलीजुली  hin\n",
       "3    jaanchon    जांचों  hin\n",
       "4    chamkata     चमकता  hin"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4f9a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roman</th>\n",
       "      <th>native</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spike</td>\n",
       "      <td>स्पाइक</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trilok</td>\n",
       "      <td>त्रिलोक</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chanda</td>\n",
       "      <td>चंदा</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meeta</td>\n",
       "      <td>मीता</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jack</td>\n",
       "      <td>जैक</td>\n",
       "      <td>hin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    roman   native lang\n",
       "0   spike   स्पाइक  hin\n",
       "1  trilok  त्रिलोक  hin\n",
       "2  chanda     चंदा  hin\n",
       "3   meeta     मीता  hin\n",
       "4    jack      जैक  hin"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c80736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        roman    native lang\n",
      "0  janamdivas  जन्मदिवस  hin\n",
      "1       rakha     रक्खा  hin\n",
      "2    milijuli  मिलीजुली  hin\n",
      "roman     0\n",
      "native    0\n",
      "lang      0\n",
      "dtype: int64\n",
      "count    6.959619e+06\n",
      "mean     1.240213e+01\n",
      "std      4.401593e+00\n",
      "min      1.000000e+00\n",
      "25%      9.000000e+00\n",
      "50%      1.200000e+01\n",
      "75%      1.600000e+01\n",
      "max      8.900000e+01\n",
      "Name: roman, dtype: float64\n",
      "count    6.959619e+06\n",
      "mean     1.078422e+01\n",
      "std      3.592192e+00\n",
      "min      1.000000e+00\n",
      "25%      8.000000e+00\n",
      "50%      1.100000e+01\n",
      "75%      1.300000e+01\n",
      "max      1.320000e+02\n",
      "Name: native, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Quick look\n",
    "print(df_train_all.head(3))\n",
    "\n",
    "# Checks for missing values\n",
    "print(df_train_all.isna().sum())\n",
    "\n",
    "# Checks string lengths (helps spot anomalies)\n",
    "print(df_train_all['roman'].str.len().describe())\n",
    "print(df_train_all['native'].str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47748b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lang             roman                   input         native\n",
      "659513   hin              mmes              <hin> mmes        एमएमईएस\n",
      "3591133  tam       elizabethan       <tam> elizabethan    எலிசபெத்தன்\n",
      "1890873  tam    nallaatchiyena    <tam> nallaatchiyena   நல்லாட்சியென\n",
      "4262937  tam   niraivaettruvar   <tam> niraivaettruvar  நிறைவேற்றுவர்\n",
      "5886910  tel       baanalingam       <tel> baanalingam       బాణలింగం\n",
      "1165657  hin            mobira            <hin> mobira         मोबिरा\n",
      "6584412  tel            janger            <tel> janger        జాంగెర్\n",
      "2596932  tam  agarathirumaalam  <tam> agarathirumaalam   அகரதிருமாளம்\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for df in [df_train_all, df_val_all]:\n",
    "    df['input'] = '<' + df['lang'] + '> ' + df['roman']\n",
    "\n",
    "# Quick look — very important check!\n",
    "print(df_train_all[['lang', 'roman', 'input', 'native']].sample(8))\n",
    "\n",
    "# Examples should look like:\n",
    "# lang  roman         input                   native\n",
    "# hin   janmadivas    <hin> janmadivas     जन्मदिवस\n",
    "# tam   vanakkam      <tam> vanakkam       வணக்கம்\n",
    "# tel   bangaram      <tel> bangaram       బంగారం"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dbd05cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>roman</th>\n",
       "      <th>input</th>\n",
       "      <th>native</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4925825</th>\n",
       "      <td>tel</td>\n",
       "      <td>shettiar</td>\n",
       "      <td>&lt;tel&gt; shettiar</td>\n",
       "      <td>శెట్టియార్</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721396</th>\n",
       "      <td>tel</td>\n",
       "      <td>bidanagar</td>\n",
       "      <td>&lt;tel&gt; bidanagar</td>\n",
       "      <td>బిదానగర్</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5054515</th>\n",
       "      <td>tel</td>\n",
       "      <td>lakshanamnu</td>\n",
       "      <td>&lt;tel&gt; lakshanamnu</td>\n",
       "      <td>లక్షణంను</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955940</th>\n",
       "      <td>hin</td>\n",
       "      <td>tattav</td>\n",
       "      <td>&lt;hin&gt; tattav</td>\n",
       "      <td>तत्तव</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707313</th>\n",
       "      <td>tam</td>\n",
       "      <td>uuttukkaarar</td>\n",
       "      <td>&lt;tam&gt; uuttukkaarar</td>\n",
       "      <td>ஊட்டுக்காரர்</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870342</th>\n",
       "      <td>hin</td>\n",
       "      <td>adhikri</td>\n",
       "      <td>&lt;hin&gt; adhikri</td>\n",
       "      <td>अधिकृ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524225</th>\n",
       "      <td>tel</td>\n",
       "      <td>osmaaniyaalloonuu</td>\n",
       "      <td>&lt;tel&gt; osmaaniyaalloonuu</td>\n",
       "      <td>ఉస్మానియాల్లోనూ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314583</th>\n",
       "      <td>tel</td>\n",
       "      <td>narasimhalayaanni</td>\n",
       "      <td>&lt;tel&gt; narasimhalayaanni</td>\n",
       "      <td>నరసింహాలయాన్ని</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lang              roman                    input           native\n",
       "4925825  tel           shettiar           <tel> shettiar       శెట్టియార్\n",
       "4721396  tel          bidanagar          <tel> bidanagar         బిదానగర్\n",
       "5054515  tel        lakshanamnu        <tel> lakshanamnu         లక్షణంను\n",
       "955940   hin             tattav             <hin> tattav            तत्तव\n",
       "2707313  tam       uuttukkaarar       <tam> uuttukkaarar     ஊட்டுக்காரர்\n",
       "870342   hin            adhikri            <hin> adhikri            अधिकृ\n",
       "6524225  tel  osmaaniyaalloonuu  <tel> osmaaniyaalloonuu  ఉస్మానియాల్లోనూ\n",
       "5314583  tel  narasimhalayaanni  <tel> narasimhalayaanni   నరసింహాలయాన్ని"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all[['lang', 'roman', 'input', 'native']].sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce0998c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples total: 6959619\n",
      "lang\n",
      "tam    0.464235\n",
      "tel    0.349094\n",
      "hin    0.186670\n",
      "Name: proportion, dtype: float64\n",
      "Empty roman: 0\n",
      "Empty native: 0\n",
      "Very short roman inputs: 52\n",
      "        roman native lang    input\n",
      "4595969     g     జీ  tel  <tel> g\n",
      "130114      p     पी  hin  <hin> p\n",
      "1361899     l   ஹால்  tam  <tam> l\n",
      "4604807     z     జి  tel  <tel> z\n",
      "4598008     l      ల  tel  <tel> l\n",
      "\n",
      "--- HIN random samples ---\n",
      "                    input       native\n",
      "228773      <hin> vedanti     वेदान्ती\n",
      "984984         <hin> liaz        लियाज\n",
      "640390     <hin> nikayama      निकायमा\n",
      "753817  <hin> parathyroid  पैराथायरायड\n",
      "362368      <hin> cicinda      सिसिंडा\n",
      "9052        <hin> bhalaai         भलाई\n",
      "\n",
      "--- TAM random samples ---\n",
      "                             input             native\n",
      "1325684        <tam> munnilaiyilum     முன்னிலையிலும்\n",
      "1401230  <tam> mananilaiyiliruntha    மனநிலையிலிருந்த\n",
      "1987819   <tam> pathividuvathendru     பதிவிடுவதென்று\n",
      "1948109         <tam> srideviyidam      ஸ்ரீதேவியிடம்\n",
      "2711701      <tam> muththamaagavum       முத்தமாகவும்\n",
      "2035522   <tam> adikkamudiyavillai  அடிக்கமுடியவில்லை\n",
      "\n",
      "--- TEL random samples ---\n",
      "                          input            native\n",
      "6356177          <tel> samiyanu           సమియాను\n",
      "5338836  <tel> kaligistunnarane  కలిగిస్తున్నారనే\n",
      "6073396           <tel> mookudu            మూకుడు\n",
      "6408794     <tel> amarachintalo         అమరచింతలో\n",
      "6476713     <tel> randhraalutho        రంధ్రాలుతో\n",
      "5529668       <tel> thodikodali         తోడికోడలి\n",
      "Duplicate input→native pairs: 0\n"
     ]
    }
   ],
   "source": [
    "# A. Basic stats\n",
    "print(\"Train examples total:\", len(df_train_all))\n",
    "print(df_train_all['lang'].value_counts(normalize=True))  # should be reasonable distribution\n",
    "\n",
    "# B. Empty or too short entries\n",
    "print(\"Empty roman:\", (df_train_all['roman'].str.strip() == '').sum())\n",
    "print(\"Empty native:\", (df_train_all['native'].str.strip() == '').sum())\n",
    "\n",
    "short_rom = df_train_all[df_train_all['roman'].str.len() < 2]\n",
    "print(\"Very short roman inputs:\", len(short_rom))\n",
    "if len(short_rom) > 0:\n",
    "    print(short_rom.sample(min(5, len(short_rom))))\n",
    "\n",
    "# C. Random samples from each language (very important!)\n",
    "for lang in ['hin', 'tam', 'tel']:\n",
    "    print(f\"\\n--- {lang.upper()} random samples ---\")\n",
    "    print(df_train_all[df_train_all['lang'] == lang][['input', 'native']].sample(6))\n",
    "\n",
    "# D. Duplicate check (optional but useful)\n",
    "print(\"Duplicate input→native pairs:\", df_train_all.duplicated(['input', 'native']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6aba1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all.to_csv('modified_dataset/clean_train_dataset.csv')\n",
    "df_val_all.to_csv('modified_dataset/clean_val_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cad933",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5655d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Keep only needed columns\n",
    "df_train = df_train_all[['input', 'native']].rename(columns={'input': 'text', 'native': 'label'})\n",
    "df_val   = df_val_all[['input', 'native']].rename(columns={'input': 'text', 'native': 'label'})\n",
    "\n",
    "train_ds = Dataset.from_pandas(df_train)\n",
    "val_ds   = Dataset.from_pandas(df_val)\n",
    "\n",
    "# Then continue with tokenizer + Seq2SeqTrainer (I can give full snippet next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e5a568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train example:\n",
      "{'text': '<hin> janamdivas', 'label': 'जन्मदिवस'}\n",
      "\n",
      "Val example:\n",
      "{'text': '<hin> sudipta', 'label': 'सुदिप्ता'}\n",
      "\n",
      "Features: {'text': Value('large_string'), 'label': Value('large_string')}\n"
     ]
    }
   ],
   "source": [
    "# Very important — look at actual examples\n",
    "print(\"\\nTrain example:\")\n",
    "print(train_ds[0])\n",
    "\n",
    "print(\"\\nVal example:\")\n",
    "print(val_ds[1234])   # random index\n",
    "\n",
    "# Check features / column names\n",
    "print(\"\\nFeatures:\", train_ds.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c4f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74586966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 192/192 [00:00<00:00, 362.63it/s, Materializing param=shared.weight]                                                       \n",
      "The tied weights mapping and config for this model specifies to tie shared.weight to encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie shared.weight to decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# Load ByT5-small\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "model_name = \"google/mt5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "print(f\"Model loaded on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ff63dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Prepare generation function\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def generate_transliteration(batch):\n",
    "    # batch = list of strings like \"<hin> kshatriya\", \"<tam> vanakkam\", ...\n",
    "    inputs = tokenizer(\n",
    "        batch,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=64\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=64,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            length_penalty=1.0,           # was 0.6 → try 1.0–2.0\n",
    "            repetition_penalty=1.2,    \n",
    "            no_repeat_ngram_size=3,       # ← prevents repeating 3-grams\n",
    "            do_sample=False,              # greedy / beam usually better here\n",
    "        )\n",
    "\n",
    "    predictions = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c749e280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:59<00:00,  5.93s/it]\n",
      "Downloading builder script: 5.13kB [00:00, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER: 1.5102\n",
      "WER: 1.0067\n",
      "Exact match accuracy: 0.0000\n",
      "\n",
      "Examples:\n",
      "Input : <hin> mehmud\n",
      "Pred  : <extra_id_0>.\n",
      "Target: मेहमूद\n",
      "\n",
      "Input : <tel> shstrachikitsa\n",
      "Pred  : <extra_id_0>\n",
      "Target: శస్త్రచికిత్స\n",
      "\n",
      "Input : <tel> maargamlo\n",
      "Pred  : <extra_id_0>\n",
      "Target: మార్గంలో\n",
      "\n",
      "Input : <tel> nruthyamu\n",
      "Pred  : <extra_id_0>\n",
      "Target: నృత్యము\n",
      "\n",
      "Input : <tam> nathiyaaga\n",
      "Pred  : <extra_id_0>.\n",
      "Target: நதியாக\n",
      "\n",
      "Input : <tel> bahishkarinchindi\n",
      "Pred  : <extra_id_0>\n",
      "Target: బహిష్కరించింది\n",
      "\n",
      "Input : <hin> jatwada\n",
      "Pred  : <extra_id_0>\n",
      "Target: जटवाड़ा\n",
      "\n",
      "Input : <hin> padegi\n",
      "Pred  : <extra_id_0>.\n",
      "Target: पड़ेगी\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Evaluate on validation set\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "# If your validation dataset is large → take a subset for baseline\n",
    "eval_dataset = val_ds.shuffle(seed=42).select(range(300))  # or val_dataset.select(range(300)) to make it faster\n",
    "\n",
    "references = []\n",
    "predictions = []\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for i in tqdm(range(0, len(eval_dataset), batch_size)):\n",
    "    batch = eval_dataset[i:i+batch_size]\n",
    "    inputs = batch[\"text\"]          # \"<hin> romanized text\" etc.\n",
    "    targets = batch[\"label\"]        # native script\n",
    "\n",
    "    preds = generate_transliteration(inputs)\n",
    "\n",
    "    predictions.extend(preds)\n",
    "    references.extend(targets)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# Compute metrics\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "cer_score = cer_metric.compute(predictions=predictions, references=references)\n",
    "wer_score = wer_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "exact_match = np.mean([p == r for p, r in zip(predictions, references)])\n",
    "\n",
    "print(f\"CER: {cer_score:.4f}\")\n",
    "print(f\"WER: {wer_score:.4f}\")\n",
    "print(f\"Exact match accuracy: {exact_match:.4f}\")\n",
    "\n",
    "# Optional: show some examples\n",
    "print(\"\\nExamples:\")\n",
    "for i in range(min(8, len(predictions))):\n",
    "    print(f\"Input : {eval_dataset[i]['text']}\")\n",
    "    print(f\"Pred  : {predictions[i]}\")\n",
    "    print(f\"Target: {references[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e826a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4136190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d3461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35558a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff332629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
